{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMRd8Z4Zrn0ewsGnCKGS7+L",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jitendra-manwani/GenAI-architect/blob/main/Jitendra_Assignmengt4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ym5vvOSmBaOH",
        "outputId": "8736e403-941d-436f-fc64-200cd4d98bab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langgraph\n",
            "  Downloading langgraph-0.4.8-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.84.0)\n",
            "Collecting chromadb\n",
            "  Downloading chromadb-1.0.12-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (4.1.0)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (2.11.5)\n",
            "Requirement already satisfied: langchain-core>=0.1 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.3.63)\n",
            "Collecting langgraph-checkpoint>=2.0.26 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-2.0.26-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting langgraph-prebuilt>=0.2.0 (from langgraph)\n",
            "  Downloading langgraph_prebuilt-0.2.2-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting langgraph-sdk>=0.1.42 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.1.70-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from langgraph) (3.5.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.14.0)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.2.2.post1)\n",
            "Collecting fastapi==0.115.9 (from chromadb)\n",
            "  Downloading fastapi-0.115.9-py3-none-any.whl.metadata (27 kB)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.34.3)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.11/dist-packages (from chromadb) (2.0.2)\n",
            "Collecting posthog>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-4.10.0-py3-none-any.whl.metadata (6.0 kB)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_api-1.34.1-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.34.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.55b1-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_sdk-1.34.1-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.21.1)\n",
            "Collecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting overrides>=7.3.1 (from chromadb)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.72.1)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Downloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.16.0)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb)\n",
            "  Downloading kubernetes-33.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (9.1.2)\n",
            "Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.0.2)\n",
            "Collecting mmh3>=4.0.1 (from chromadb)\n",
            "  Downloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.10.18)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.24.0)\n",
            "Collecting starlette<0.46.0,>=0.40.0 (from fastapi==0.115.9->chromadb)\n",
            "  Downloading starlette-0.45.3-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.52.4)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.32.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.2.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic) (0.4.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (24.2)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.25.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.38.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.4.0)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
            "  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.126 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (0.3.44)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
            "Collecting ormsgpack<2.0.0,>=1.8.0 (from langgraph-checkpoint>=2.0.26->langgraph)\n",
            "  Downloading ormsgpack-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.70.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.34.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.34.1-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting opentelemetry-proto==1.34.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_proto-1.34.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-instrumentation-asgi==0.55b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.55b1-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting opentelemetry-instrumentation==0.55b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation-0.55b1-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.55b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_semantic_conventions-0.55b1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting opentelemetry-util-http==0.55b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_util_http-0.55b1-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation==0.55b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.2)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.55b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (2.19.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-1.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.22.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.1->langgraph) (3.0.0)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.126->langchain-core>=0.1->langgraph) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.126->langchain-core>=0.1->langgraph) (0.23.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.2)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
            "Downloading langgraph-0.4.8-py3-none-any.whl (152 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.4/152.4 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chromadb-1.0.12-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.3/19.3 MB\u001b[0m \u001b[31m85.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.115.9-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl (284 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kubernetes-33.1.0-py2.py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m71.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-2.0.26-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.2/44.2 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_prebuilt-0.2.2-py3-none-any.whl (23 kB)\n",
            "Downloading langgraph_sdk-0.1.70-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.0/50.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m93.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_api-1.34.1-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.8/65.8 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.34.1-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.34.1-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.34.1-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.7/55.7 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_instrumentation_fastapi-0.55b1-py3-none-any.whl (12 kB)\n",
            "Downloading opentelemetry_instrumentation-0.55b1-py3-none-any.whl (31 kB)\n",
            "Downloading opentelemetry_instrumentation_asgi-0.55b1-py3-none-any.whl (16 kB)\n",
            "Downloading opentelemetry_semantic_conventions-0.55b1-py3-none-any.whl (196 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.2/196.2 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_util_http-0.55b1-py3-none-any.whl (7.3 kB)\n",
            "Downloading opentelemetry_sdk-1.34.1-py3-none-any.whl (118 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.5/118.5 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading posthog-4.10.0-py3-none-any.whl (102 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.5/102.5 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m55.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
            "Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ormsgpack-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (216 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.5/216.5 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading starlette-0.45.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m78.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (454 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.8/454.8 kB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
            "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53803 sha256=941c341a0d57d8027945e41bd81427a232f5ee57c737a443128473c11a25255f\n",
            "  Stored in directory: /root/.cache/pip/wheels/a3/01/bd/4c40ceb9d5354160cb186dcc153360f4ab7eb23e2b24daf96d\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, durationpy, uvloop, python-dotenv, overrides, ormsgpack, opentelemetry-util-http, opentelemetry-proto, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, mmh3, humanfriendly, httptools, bcrypt, backoff, asgiref, watchfiles, starlette, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, nvidia-cusparse-cu12, nvidia-cudnn-cu12, coloredlogs, opentelemetry-semantic-conventions, onnxruntime, nvidia-cusolver-cu12, langgraph-sdk, kubernetes, fastapi, opentelemetry-sdk, opentelemetry-instrumentation, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, langgraph-checkpoint, opentelemetry-instrumentation-fastapi, langgraph-prebuilt, langgraph, chromadb\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: starlette\n",
            "    Found existing installation: starlette 0.46.2\n",
            "    Uninstalling starlette-0.46.2:\n",
            "      Successfully uninstalled starlette-0.46.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: fastapi\n",
            "    Found existing installation: fastapi 0.115.12\n",
            "    Uninstalling fastapi-0.115.12:\n",
            "      Successfully uninstalled fastapi-0.115.12\n",
            "Successfully installed asgiref-3.8.1 backoff-2.2.1 bcrypt-4.3.0 chromadb-1.0.12 coloredlogs-15.0.1 durationpy-0.10 fastapi-0.115.9 httptools-0.6.4 humanfriendly-10.0 kubernetes-33.1.0 langgraph-0.4.8 langgraph-checkpoint-2.0.26 langgraph-prebuilt-0.2.2 langgraph-sdk-0.1.70 mmh3-5.1.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 onnxruntime-1.22.0 opentelemetry-api-1.34.1 opentelemetry-exporter-otlp-proto-common-1.34.1 opentelemetry-exporter-otlp-proto-grpc-1.34.1 opentelemetry-instrumentation-0.55b1 opentelemetry-instrumentation-asgi-0.55b1 opentelemetry-instrumentation-fastapi-0.55b1 opentelemetry-proto-1.34.1 opentelemetry-sdk-1.34.1 opentelemetry-semantic-conventions-0.55b1 opentelemetry-util-http-0.55b1 ormsgpack-1.10.0 overrides-7.7.0 posthog-4.10.0 pypika-0.48.9 python-dotenv-1.1.0 starlette-0.45.3 uvloop-0.21.0 watchfiles-1.0.5\n"
          ]
        }
      ],
      "source": [
        "# Assignment 4\n",
        "# Simplified Agentic RAG System with LangGraph\n",
        "\n",
        "\n",
        "# =====================================\n",
        "# STEP 1: Install Required Packages\n",
        "# =====================================\n",
        "\n",
        "!pip install langgraph openai chromadb sentence-transformers pydantic"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================\n",
        "# STEP 2: Import Libraries and Setup\n",
        "# =====================================\n",
        "\n",
        "import json\n",
        "import os\n",
        "from typing import List, Dict, Any\n",
        "import openai\n",
        "from openai import AzureOpenAI\n",
        "import chromadb\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from langgraph.graph import Graph\n",
        "import uuid"
      ],
      "metadata": {
        "id": "RUACeEaLBpCY"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up Azure OpenAI configuration\n",
        "# Replace these with your actual Azure OpenAI credentials\n",
        "AZURE_OPENAI_ENDPOINT = \"https://eastus.api.cognitive.microsoft.com/\"\n",
        "AZURE_OPENAI_KEY = \"63a0587ef7b24ca9b5d7b179c13fbaab\"\n",
        "AZURE_DEPLOYMENT_NAME = \"telcogpt\"\n",
        "\n",
        "# Create Azure OpenAI client\n",
        "client = AzureOpenAI(\n",
        "    azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
        "    api_key=AZURE_OPENAI_KEY,\n",
        "    api_version=\"2024-12-01-preview\"\n",
        ")"
      ],
      "metadata": {
        "id": "0jbp6QpMBpFN"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize embedding model (using sentence-transformers for simplicity)\n",
        "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Initialize Chroma DB\n",
        "chroma_client = chromadb.Client()\n",
        "\n",
        "print(\"Setup complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TDYwaoVaBpHX",
        "outputId": "38f77c3f-ac1b-4d6a-fd06-8e944154eab3"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================\n",
        "# STEP 3: Create Sample Dataset\n",
        "# =====================================\n",
        "\n",
        "# Since we don't have the actual JSON file, let's create a sample dataset\n",
        "sample_kb_data = [\n",
        "    {\n",
        "        \"doc_id\": \"KB001\",\n",
        "        \"question\": \"What are best practices for debugging?\",\n",
        "        \"answer_snippet\": \"When debugging, start with a minimal reproducible test case, use systematic logging at key points, apply divide-and-conquer approach to isolate the issue, and use debugger tools effectively.\",\n",
        "        \"source\": \"debugging_guide.md\",\n",
        "        \"last_updated\": \"2024-01-10\"\n",
        "    },\n",
        "    {\n",
        "        \"doc_id\": \"KB002\",\n",
        "        \"question\": \"What are performance tuning tips?\",\n",
        "        \"answer_snippet\": \"For performance tuning, profile your application first to identify bottlenecks, optimize database queries, implement caching strategies, and monitor resource usage continuously.\",\n",
        "        \"source\": \"performance_guide.md\",\n",
        "        \"last_updated\": \"2024-01-15\"\n",
        "    },\n",
        "    {\n",
        "        \"doc_id\": \"KB003\",\n",
        "        \"question\": \"What are best practices for caching?\",\n",
        "        \"answer_snippet\": \"Implement cache-aside pattern, set appropriate TTL values, use cache hierarchies for different data types, and implement cache warming strategies for critical data.\",\n",
        "        \"source\": \"caching_guide.md\",\n",
        "        \"last_updated\": \"2024-01-20\"\n",
        "    },\n",
        "    {\n",
        "        \"doc_id\": \"KB004\",\n",
        "        \"question\": \"How should I set up CI/CD pipelines?\",\n",
        "        \"answer_snippet\": \"Set up automated testing at multiple levels, use infrastructure as code, implement gradual rollouts, and maintain separate environments for development, staging, and production.\",\n",
        "        \"source\": \"cicd_guide.md\",\n",
        "        \"last_updated\": \"2024-01-25\"\n",
        "    },\n",
        "    {\n",
        "        \"doc_id\": \"KB005\",\n",
        "        \"question\": \"How do I version my APIs?\",\n",
        "        \"answer_snippet\": \"Use semantic versioning (major.minor.patch), maintain backward compatibility when possible, provide clear migration guides, and deprecate old versions gradually.\",\n",
        "        \"source\": \"api_guide.md\",\n",
        "        \"last_updated\": \"2024-02-01\"\n",
        "    },\n",
        "    {\n",
        "        \"doc_id\": \"KB006\",\n",
        "        \"question\": \"What should I consider for error handling?\",\n",
        "        \"answer_snippet\": \"Implement structured exception handling, log errors with sufficient context, provide meaningful error messages to users, and implement retry mechanisms for transient failures.\",\n",
        "        \"source\": \"error_handling_guide.md\",\n",
        "        \"last_updated\": \"2024-02-05\"\n",
        "    },\n",
        "    {\n",
        "        \"doc_id\": \"KB007\",\n",
        "        \"question\": \"What are CI/CD pipeline best practices?\",\n",
        "        \"answer_snippet\": \"Use automated testing, implement blue-green deployments, maintain deployment scripts in version control, and monitor deployment metrics.\",\n",
        "        \"source\": \"pipeline_guide.md\",\n",
        "        \"last_updated\": \"2024-02-10\"\n",
        "    },\n",
        "    {\n",
        "        \"doc_id\": \"KB008\",\n",
        "        \"question\": \"How to implement cache invalidation?\",\n",
        "        \"answer_snippet\": \"Use time-based expiration, implement cache tags for grouped invalidation, use event-driven invalidation, and consider cache coherence in distributed systems.\",\n",
        "        \"source\": \"cache_invalidation_guide.md\",\n",
        "        \"last_updated\": \"2024-02-12\"\n",
        "    },\n",
        "    {\n",
        "        \"doc_id\": \"KB009\",\n",
        "        \"question\": \"What are profiling tools for performance?\",\n",
        "        \"answer_snippet\": \"Use application performance monitoring tools, implement custom metrics, use database query analyzers, and monitor system resource usage with tools like htop or Performance Monitor.\",\n",
        "        \"source\": \"profiling_guide.md\",\n",
        "        \"last_updated\": \"2024-02-15\"\n",
        "    },\n",
        "    {\n",
        "        \"doc_id\": \"KB010\",\n",
        "        \"question\": \"What is semantic versioning?\",\n",
        "        \"answer_snippet\": \"Semantic versioning uses MAJOR.MINOR.PATCH format where MAJOR version changes break compatibility, MINOR version adds functionality, and PATCH version fixes bugs.\",\n",
        "        \"source\": \"versioning_guide.md\",\n",
        "        \"last_updated\": \"2024-02-18\"\n",
        "    }\n",
        "]\n",
        "\n",
        "print(f\"Created sample dataset with {len(sample_kb_data)} entries\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FT8ftjT2BpKB",
        "outputId": "c5f44d6c-cf39-4ca6-ec7e-cbf67e623202"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created sample dataset with 10 entries\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================\n",
        "# CELL 4: Index Knowledge Base\n",
        "# =====================================\n",
        "\n",
        "# Create or get collection\n",
        "try:\n",
        "    collection = chroma_client.create_collection(name=\"kb_collection\")\n",
        "except:\n",
        "    chroma_client.delete_collection(name=\"kb_collection\")\n",
        "    collection = chroma_client.create_collection(name=\"kb_collection\")\n",
        "\n",
        "# Process and index each document\n",
        "documents = []\n",
        "metadatas = []\n",
        "ids = []\n",
        "embeddings = []\n",
        "\n",
        "for item in sample_kb_data:\n",
        "    # Generate embedding for the answer snippet\n",
        "    embedding = embedding_model.encode(item[\"answer_snippet\"]).tolist()\n",
        "\n",
        "    documents.append(item[\"answer_snippet\"])\n",
        "    metadatas.append({\n",
        "        \"doc_id\": item[\"doc_id\"],\n",
        "        \"source\": item[\"source\"],\n",
        "        \"last_updated\": item[\"last_updated\"],\n",
        "        \"question\": item[\"question\"]\n",
        "    })\n",
        "    ids.append(item[\"doc_id\"])\n",
        "    embeddings.append(embedding)\n",
        "\n",
        "# Add to collection\n",
        "collection.add(\n",
        "    embeddings=embeddings,\n",
        "    documents=documents,\n",
        "    metadatas=metadatas,\n",
        "    ids=ids\n",
        ")\n",
        "\n",
        "print(f\"Indexed {len(documents)} documents successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SkZCM1DvBpMY",
        "outputId": "65843c6e-1d6e-441d-8d57-4432b8ff1442"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Indexed 10 documents successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================\n",
        "# STEP 5: Define RAG Components\n",
        "# =====================================\n",
        "\n",
        "def retrieve_kb(user_question: str, top_k: int = 5) -> List[Dict]:\n",
        "    \"\"\"Retrieve top-k relevant documents from knowledge base\"\"\"\n",
        "    query_embedding = embedding_model.encode(user_question).tolist()\n",
        "\n",
        "    results = collection.query(\n",
        "        query_embeddings=[query_embedding],\n",
        "        n_results=top_k\n",
        "    )\n",
        "\n",
        "    retrieved_docs = []\n",
        "    for i in range(len(results['ids'][0])):\n",
        "        retrieved_docs.append({\n",
        "            \"doc_id\": results['metadatas'][0][i]['doc_id'],\n",
        "            \"answer_snippet\": results['documents'][0][i],\n",
        "            \"source\": results['metadatas'][0][i]['source'],\n",
        "            \"distance\": results['distances'][0][i]\n",
        "        })\n",
        "\n",
        "    return retrieved_docs\n",
        "\n",
        "def generate_answer(user_question: str, kb_hits: List[Dict]) -> str:\n",
        "    \"\"\"Generate initial answer using retrieved context\"\"\"\n",
        "\n",
        "    # Format retrieved snippets\n",
        "    snippets_text = \"\"\n",
        "    for hit in kb_hits:\n",
        "        snippets_text += f\"[{hit['doc_id']}] {hit['answer_snippet']}\\n\\n\"\n",
        "\n",
        "    prompt = f\"\"\"You are a software best-practices assistant.\n",
        "\n",
        "User Question:\n",
        "{user_question}\n",
        "\n",
        "Retrieved Snippets:\n",
        "{snippets_text}\n",
        "\n",
        "Task:\n",
        "Based on these snippets, write a concise answer to the user's question.\n",
        "Cite each snippet you use by its doc_id in square brackets (e.g., [KB004]).\n",
        "Return only the answer text.\"\"\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=AZURE_DEPLOYMENT_NAME,\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=0\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "def critique_answer(user_question: str, initial_answer: str, kb_hits: List[Dict]) -> str:\n",
        "    \"\"\"Critique the initial answer for completeness\"\"\"\n",
        "\n",
        "    # Format KB snippets\n",
        "    snippets_text = \"\"\n",
        "    for hit in kb_hits:\n",
        "        snippets_text += f\"[{hit['doc_id']}] {hit['answer_snippet']}\\n\\n\"\n",
        "\n",
        "    prompt = f\"\"\"You are a critical QA assistant. The user asked: {user_question}\n",
        "\n",
        "Initial Answer:\n",
        "{initial_answer}\n",
        "\n",
        "KB Snippets:\n",
        "{snippets_text}\n",
        "\n",
        "Task:\n",
        "Determine if the initial answer fully addresses the question using only these snippets.\n",
        "- If it does, respond exactly: COMPLETE\n",
        "- If it misses any point or cites missing info, respond: REFINE: <short list of missing topic keywords>\n",
        "\n",
        "Return exactly one line.\"\"\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=AZURE_DEPLOYMENT_NAME,\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=0\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content.strip()\n",
        "\n",
        "def refine_answer(user_question: str, initial_answer: str, critique_result: str, kb_hits: List[Dict]) -> str:\n",
        "    \"\"\"Refine answer based on critique\"\"\"\n",
        "\n",
        "    # Extract missing keywords from critique\n",
        "    missing_keywords = critique_result.replace(\"REFINE:\", \"\").strip()\n",
        "\n",
        "    # Build new query and retrieve additional snippet\n",
        "    new_query = f\"{user_question} {missing_keywords}\"\n",
        "    additional_snippet = retrieve_kb(new_query, top_k=1)[0]\n",
        "\n",
        "    prompt = f\"\"\"You are a software best-practices assistant refining your answer.\n",
        "\n",
        "User Question: {user_question}\n",
        "\n",
        "Initial Answer:\n",
        "{initial_answer}\n",
        "\n",
        "Critique: {critique_result}\n",
        "\n",
        "Additional Snippet:\n",
        "[{additional_snippet['doc_id']}] {additional_snippet['answer_snippet']}\n",
        "\n",
        "Task:\n",
        "Incorporate this snippet into the answer, covering the missing points.\n",
        "Cite any snippet you use by doc_id in square brackets.\n",
        "Return only the final refined answer.\"\"\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=AZURE_DEPLOYMENT_NAME,\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=0\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "print(\"RAG components defined successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zIEC54ooBpPN",
        "outputId": "fc9350ab-0d51-48d0-e65c-2e4c4373cc2d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RAG components defined successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================\n",
        "# CELL 6: Test the Pipeline with Sample Queries\n",
        "# =====================================\n",
        "\n",
        "# Test queries from the assignment\n",
        "test_queries = [\n",
        "    \"What are best practices for caching?\",\n",
        "    \"How should I set up CI/CD pipelines?\",\n",
        "    \"What are performance tuning tips?\",\n",
        "    \"How do I version my APIs?\",\n",
        "    \"What should I consider for error handling?\"\n",
        "]\n",
        "\n",
        "# Process each query\n",
        "for i, query in enumerate(test_queries, 1):\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"TEST QUERY {i}: {query}\")\n",
        "    print('='*60)\n",
        "\n",
        "    # Step 1: Retrieve relevant documents\n",
        "    print(\"\\n1. RETRIEVING RELEVANT DOCUMENTS...\")\n",
        "    kb_hits = retrieve_kb(query, top_k=5)\n",
        "\n",
        "    for j, hit in enumerate(kb_hits):\n",
        "        print(f\"   [{hit['doc_id']}] Score: {hit['distance']:.3f}\")\n",
        "        print(f\"   {hit['answer_snippet'][:100]}...\")\n",
        "        print()\n",
        "\n",
        "    # Step 2: Generate initial answer\n",
        "    print(\"2. GENERATING INITIAL ANSWER...\")\n",
        "    initial_answer = generate_answer(query, kb_hits)\n",
        "    print(f\"Initial Answer: {initial_answer}\")\n",
        "\n",
        "    # Step 3: Critique the answer\n",
        "    print(\"\\n3. CRITIQUING ANSWER...\")\n",
        "    critique_result = critique_answer(query, initial_answer, kb_hits)\n",
        "    print(f\"Critique Result: {critique_result}\")\n",
        "\n",
        "    # Step 4: Refine if needed\n",
        "    final_answer = initial_answer\n",
        "\n",
        "    if critique_result.startswith(\"REFINE\"):\n",
        "        print(\"\\n4. REFINING ANSWER...\")\n",
        "        final_answer = refine_answer(query, initial_answer, critique_result, kb_hits)\n",
        "        print(f\"Refined Answer: {final_answer}\")\n",
        "    else:\n",
        "        print(\"\\n4. NO REFINEMENT NEEDED\")\n",
        "\n",
        "    # Final JSON response\n",
        "    final_response = {\"answer\": final_answer}\n",
        "    print(f\"\\n5. FINAL JSON RESPONSE:\")\n",
        "    print(json.dumps(final_response, indent=2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "reKIDwtcBpR0",
        "outputId": "a82b964e-93f2-42ef-8697-3beedda68aff"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "TEST QUERY 1: What are best practices for caching?\n",
            "============================================================\n",
            "\n",
            "1. RETRIEVING RELEVANT DOCUMENTS...\n",
            "   [KB003] Score: 0.701\n",
            "   Implement cache-aside pattern, set appropriate TTL values, use cache hierarchies for different data ...\n",
            "\n",
            "   [KB008] Score: 0.738\n",
            "   Use time-based expiration, implement cache tags for grouped invalidation, use event-driven invalidat...\n",
            "\n",
            "   [KB002] Score: 1.071\n",
            "   For performance tuning, profile your application first to identify bottlenecks, optimize database qu...\n",
            "\n",
            "   [KB009] Score: 1.403\n",
            "   Use application performance monitoring tools, implement custom metrics, use database query analyzers...\n",
            "\n",
            "   [KB005] Score: 1.406\n",
            "   Use semantic versioning (major.minor.patch), maintain backward compatibility when possible, provide ...\n",
            "\n",
            "2. GENERATING INITIAL ANSWER...\n",
            "Initial Answer: Best practices for caching include implementing the cache-aside pattern, setting appropriate time-to-live (TTL) values, and using cache hierarchies for different data types. Additionally, consider cache warming strategies for critical data, use time-based expiration, and implement cache tags for grouped invalidation. Event-driven invalidation and cache coherence are important in distributed systems as well [KB003][KB008]. For performance tuning, profile your application to identify bottlenecks, optimize database queries, and continuously monitor resource usage [KB002].\n",
            "\n",
            "3. CRITIQUING ANSWER...\n",
            "Critique Result: COMPLETE\n",
            "\n",
            "4. NO REFINEMENT NEEDED\n",
            "\n",
            "5. FINAL JSON RESPONSE:\n",
            "{\n",
            "  \"answer\": \"Best practices for caching include implementing the cache-aside pattern, setting appropriate time-to-live (TTL) values, and using cache hierarchies for different data types. Additionally, consider cache warming strategies for critical data, use time-based expiration, and implement cache tags for grouped invalidation. Event-driven invalidation and cache coherence are important in distributed systems as well [KB003][KB008]. For performance tuning, profile your application to identify bottlenecks, optimize database queries, and continuously monitor resource usage [KB002].\"\n",
            "}\n",
            "\n",
            "============================================================\n",
            "TEST QUERY 2: How should I set up CI/CD pipelines?\n",
            "============================================================\n",
            "\n",
            "1. RETRIEVING RELEVANT DOCUMENTS...\n",
            "   [KB004] Score: 1.207\n",
            "   Set up automated testing at multiple levels, use infrastructure as code, implement gradual rollouts,...\n",
            "\n",
            "   [KB007] Score: 1.356\n",
            "   Use automated testing, implement blue-green deployments, maintain deployment scripts in version cont...\n",
            "\n",
            "   [KB003] Score: 1.663\n",
            "   Implement cache-aside pattern, set appropriate TTL values, use cache hierarchies for different data ...\n",
            "\n",
            "   [KB008] Score: 1.668\n",
            "   Use time-based expiration, implement cache tags for grouped invalidation, use event-driven invalidat...\n",
            "\n",
            "   [KB006] Score: 1.712\n",
            "   Implement structured exception handling, log errors with sufficient context, provide meaningful erro...\n",
            "\n",
            "2. GENERATING INITIAL ANSWER...\n",
            "Initial Answer: To set up CI/CD pipelines, you should implement automated testing at multiple levels and use infrastructure as code to ensure consistency across environments. Maintain separate environments for development, staging, and production to facilitate safe deployments. Consider using blue-green deployments for minimal downtime and monitor deployment metrics to assess performance and reliability. Additionally, keep your deployment scripts in version control to track changes effectively [KB004][KB007].\n",
            "\n",
            "3. CRITIQUING ANSWER...\n",
            "Critique Result: COMPLETE\n",
            "\n",
            "4. NO REFINEMENT NEEDED\n",
            "\n",
            "5. FINAL JSON RESPONSE:\n",
            "{\n",
            "  \"answer\": \"To set up CI/CD pipelines, you should implement automated testing at multiple levels and use infrastructure as code to ensure consistency across environments. Maintain separate environments for development, staging, and production to facilitate safe deployments. Consider using blue-green deployments for minimal downtime and monitor deployment metrics to assess performance and reliability. Additionally, keep your deployment scripts in version control to track changes effectively [KB004][KB007].\"\n",
            "}\n",
            "\n",
            "============================================================\n",
            "TEST QUERY 3: What are performance tuning tips?\n",
            "============================================================\n",
            "\n",
            "1. RETRIEVING RELEVANT DOCUMENTS...\n",
            "   [KB002] Score: 0.868\n",
            "   For performance tuning, profile your application first to identify bottlenecks, optimize database qu...\n",
            "\n",
            "   [KB003] Score: 1.296\n",
            "   Implement cache-aside pattern, set appropriate TTL values, use cache hierarchies for different data ...\n",
            "\n",
            "   [KB009] Score: 1.327\n",
            "   Use application performance monitoring tools, implement custom metrics, use database query analyzers...\n",
            "\n",
            "   [KB004] Score: 1.546\n",
            "   Set up automated testing at multiple levels, use infrastructure as code, implement gradual rollouts,...\n",
            "\n",
            "   [KB007] Score: 1.548\n",
            "   Use automated testing, implement blue-green deployments, maintain deployment scripts in version cont...\n",
            "\n",
            "2. GENERATING INITIAL ANSWER...\n",
            "Initial Answer: To optimize performance, start by profiling your application to identify bottlenecks and optimize database queries. Implement caching strategies, such as the cache-aside pattern, and set appropriate TTL values for cached data [KB002][KB003]. Use application performance monitoring tools and custom metrics to continuously monitor resource usage [KB009]. Additionally, consider setting up automated testing and maintaining separate environments for development, staging, and production to ensure stability during updates [KB004].\n",
            "\n",
            "3. CRITIQUING ANSWER...\n",
            "Critique Result: REFINE: cache hierarchies, cache warming strategies, blue-green deployments, deployment metrics\n",
            "\n",
            "4. REFINING ANSWER...\n",
            "Refined Answer: To optimize performance, start by profiling your application to identify bottlenecks and optimize database queries [KB002]. Implement caching strategies, such as cache hierarchies and the cache-aside pattern, and consider cache warming strategies to pre-load frequently accessed data. Set appropriate TTL values for cached data to balance freshness and performance. Use application performance monitoring tools and custom metrics to continuously monitor resource usage [KB009]. Additionally, consider blue-green deployments to minimize downtime during updates and ensure stability. Establish automated testing and maintain separate environments for development, staging, and production to further enhance stability and performance during updates [KB004].\n",
            "\n",
            "5. FINAL JSON RESPONSE:\n",
            "{\n",
            "  \"answer\": \"To optimize performance, start by profiling your application to identify bottlenecks and optimize database queries [KB002]. Implement caching strategies, such as cache hierarchies and the cache-aside pattern, and consider cache warming strategies to pre-load frequently accessed data. Set appropriate TTL values for cached data to balance freshness and performance. Use application performance monitoring tools and custom metrics to continuously monitor resource usage [KB009]. Additionally, consider blue-green deployments to minimize downtime during updates and ensure stability. Establish automated testing and maintain separate environments for development, staging, and production to further enhance stability and performance during updates [KB004].\"\n",
            "}\n",
            "\n",
            "============================================================\n",
            "TEST QUERY 4: How do I version my APIs?\n",
            "============================================================\n",
            "\n",
            "1. RETRIEVING RELEVANT DOCUMENTS...\n",
            "   [KB005] Score: 0.856\n",
            "   Use semantic versioning (major.minor.patch), maintain backward compatibility when possible, provide ...\n",
            "\n",
            "   [KB010] Score: 1.219\n",
            "   Semantic versioning uses MAJOR.MINOR.PATCH format where MAJOR version changes break compatibility, M...\n",
            "\n",
            "   [KB007] Score: 1.339\n",
            "   Use automated testing, implement blue-green deployments, maintain deployment scripts in version cont...\n",
            "\n",
            "   [KB004] Score: 1.501\n",
            "   Set up automated testing at multiple levels, use infrastructure as code, implement gradual rollouts,...\n",
            "\n",
            "   [KB008] Score: 1.700\n",
            "   Use time-based expiration, implement cache tags for grouped invalidation, use event-driven invalidat...\n",
            "\n",
            "2. GENERATING INITIAL ANSWER...\n",
            "Initial Answer: To version your APIs, use semantic versioning in the format MAJOR.MINOR.PATCH, where MAJOR version changes indicate breaking changes, MINOR version changes add functionality, and PATCH version changes fix bugs. Aim to maintain backward compatibility when possible, provide clear migration guides for users, and gradually deprecate old versions to ease transitions [KB005][KB010].\n",
            "\n",
            "3. CRITIQUING ANSWER...\n",
            "Critique Result: COMPLETE\n",
            "\n",
            "4. NO REFINEMENT NEEDED\n",
            "\n",
            "5. FINAL JSON RESPONSE:\n",
            "{\n",
            "  \"answer\": \"To version your APIs, use semantic versioning in the format MAJOR.MINOR.PATCH, where MAJOR version changes indicate breaking changes, MINOR version changes add functionality, and PATCH version changes fix bugs. Aim to maintain backward compatibility when possible, provide clear migration guides for users, and gradually deprecate old versions to ease transitions [KB005][KB010].\"\n",
            "}\n",
            "\n",
            "============================================================\n",
            "TEST QUERY 5: What should I consider for error handling?\n",
            "============================================================\n",
            "\n",
            "1. RETRIEVING RELEVANT DOCUMENTS...\n",
            "   [KB006] Score: 0.695\n",
            "   Implement structured exception handling, log errors with sufficient context, provide meaningful erro...\n",
            "\n",
            "   [KB008] Score: 1.149\n",
            "   Use time-based expiration, implement cache tags for grouped invalidation, use event-driven invalidat...\n",
            "\n",
            "   [KB001] Score: 1.425\n",
            "   When debugging, start with a minimal reproducible test case, use systematic logging at key points, a...\n",
            "\n",
            "   [KB002] Score: 1.545\n",
            "   For performance tuning, profile your application first to identify bottlenecks, optimize database qu...\n",
            "\n",
            "   [KB004] Score: 1.557\n",
            "   Set up automated testing at multiple levels, use infrastructure as code, implement gradual rollouts,...\n",
            "\n",
            "2. GENERATING INITIAL ANSWER...\n",
            "Initial Answer: When considering error handling, you should implement structured exception handling, log errors with sufficient context, and provide meaningful error messages to users. Additionally, consider implementing retry mechanisms for transient failures to enhance resilience in your application [KB006].\n",
            "\n",
            "3. CRITIQUING ANSWER...\n",
            "Critique Result: COMPLETE\n",
            "\n",
            "4. NO REFINEMENT NEEDED\n",
            "\n",
            "5. FINAL JSON RESPONSE:\n",
            "{\n",
            "  \"answer\": \"When considering error handling, you should implement structured exception handling, log errors with sufficient context, and provide meaningful error messages to users. Additionally, consider implementing retry mechanisms for transient failures to enhance resilience in your application [KB006].\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4h1MxGQiFvTF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}